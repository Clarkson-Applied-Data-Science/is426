{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo a large datafile in excel / notepad\n",
    "# gc log.txt | select -first 10\n",
    "# Get-Content log.txt -Tail 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af41df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4485\n"
     ]
    }
   ],
   "source": [
    "#  We can open files line by line to reduce memory usage.\n",
    "# discuss \n",
    "# -dataformat (lists)\n",
    "# -printing\n",
    "# -etc.\n",
    "import csv\n",
    "fn = 'data/wifi_list.csv'\n",
    "\n",
    "f = open(fn, 'r')\n",
    "reader = csv.reader(f)\n",
    "n = 0\n",
    "for row in reader:\n",
    "    if n % 100000 == 0:\n",
    "        print(n)\n",
    "    n+=1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a script which imports all Atlantic storms data from data/storms.csv\n",
    "# (modify last weeks script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subsets\n",
    "# Create a smaller subset of a very large CSV:\n",
    "import csv\n",
    "\n",
    "#load the input file\n",
    "f1 = open('data/wifi_list.csv','r')\n",
    "reader = csv.reader(f1)\n",
    "\n",
    "#clear the destination file\n",
    "f = open('data/wifi_subset.csv', 'w', newline ='')\n",
    "f.write('')\n",
    "f.close()\n",
    "\n",
    "#open destination for appending \n",
    "f = open('data/wifi_subset.csv', 'a', newline ='')\n",
    "writer = csv.writer(f)\n",
    "n=0\n",
    "subset_size = 100\n",
    "for row in reader:\n",
    "    writer.writerow(row)\n",
    "    n+=1\n",
    "    if n > subset_size:\n",
    "        break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.executemany()\n",
    "#insert storms.csv using this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-reverse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reliable-stretch",
   "metadata": {},
   "source": [
    "To Know:\n",
    "* Be able to profile scripts and get a sense of which part is slowest.\n",
    "* Be able to work with a large CSV in a memory conscious way.\n",
    "  * iteration line by line\n",
    "  * Printing\n",
    "  * executemany()\n",
    "* Be able to write a script which inserts / filters / subsets that data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-correspondence",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-conjunction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d4d69e597880b9b60eb0be4f89ec7c27c2bb88050820adbecd4ead6dbb8e32e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
